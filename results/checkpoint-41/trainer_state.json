{
  "best_global_step": 41,
  "best_metric": 0.6383993625640869,
  "best_model_checkpoint": "results/checkpoint-41",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 41,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.024390243902439025,
      "grad_norm": 10.109831809997559,
      "learning_rate": 0.0002,
      "loss": 0.8106495141983032,
      "step": 1
    },
    {
      "epoch": 0.04878048780487805,
      "grad_norm": 11.067046165466309,
      "learning_rate": 0.0001983739837398374,
      "loss": 0.479077011346817,
      "step": 2
    },
    {
      "epoch": 0.07317073170731707,
      "grad_norm": 4.262631893157959,
      "learning_rate": 0.00019674796747967482,
      "loss": 0.7227815985679626,
      "step": 3
    },
    {
      "epoch": 0.0975609756097561,
      "grad_norm": 3.5753395557403564,
      "learning_rate": 0.0001951219512195122,
      "loss": 0.6665862202644348,
      "step": 4
    },
    {
      "epoch": 0.12195121951219512,
      "grad_norm": 9.50108814239502,
      "learning_rate": 0.00019349593495934962,
      "loss": 0.8383647799491882,
      "step": 5
    },
    {
      "epoch": 0.14634146341463414,
      "grad_norm": 8.757197380065918,
      "learning_rate": 0.000191869918699187,
      "loss": 0.6175611019134521,
      "step": 6
    },
    {
      "epoch": 0.17073170731707318,
      "grad_norm": 14.840785026550293,
      "learning_rate": 0.0001902439024390244,
      "loss": 0.7164916396141052,
      "step": 7
    },
    {
      "epoch": 0.1951219512195122,
      "grad_norm": 3.4776771068573,
      "learning_rate": 0.0001886178861788618,
      "loss": 0.8517243266105652,
      "step": 8
    },
    {
      "epoch": 0.21951219512195122,
      "grad_norm": 2.4558606147766113,
      "learning_rate": 0.00018699186991869918,
      "loss": 0.6721346378326416,
      "step": 9
    },
    {
      "epoch": 0.24390243902439024,
      "grad_norm": 2.4481067657470703,
      "learning_rate": 0.0001853658536585366,
      "loss": 0.6603900194168091,
      "step": 10
    },
    {
      "epoch": 0.2682926829268293,
      "grad_norm": 5.9095234870910645,
      "learning_rate": 0.000183739837398374,
      "loss": 0.6636172533035278,
      "step": 11
    },
    {
      "epoch": 0.2926829268292683,
      "grad_norm": 9.116265296936035,
      "learning_rate": 0.00018211382113821138,
      "loss": 0.7263493537902832,
      "step": 12
    },
    {
      "epoch": 0.3170731707317073,
      "grad_norm": 4.604400634765625,
      "learning_rate": 0.0001804878048780488,
      "loss": 0.7269477248191833,
      "step": 13
    },
    {
      "epoch": 0.34146341463414637,
      "grad_norm": 6.81760835647583,
      "learning_rate": 0.00017886178861788618,
      "loss": 0.6372758746147156,
      "step": 14
    },
    {
      "epoch": 0.36585365853658536,
      "grad_norm": 5.2701592445373535,
      "learning_rate": 0.0001772357723577236,
      "loss": 0.5996804237365723,
      "step": 15
    },
    {
      "epoch": 0.3902439024390244,
      "grad_norm": 3.435281753540039,
      "learning_rate": 0.000175609756097561,
      "loss": 0.5770020484924316,
      "step": 16
    },
    {
      "epoch": 0.4146341463414634,
      "grad_norm": 2.9955577850341797,
      "learning_rate": 0.00017398373983739838,
      "loss": 0.7556462287902832,
      "step": 17
    },
    {
      "epoch": 0.43902439024390244,
      "grad_norm": 2.614231586456299,
      "learning_rate": 0.0001723577235772358,
      "loss": 0.6341516375541687,
      "step": 18
    },
    {
      "epoch": 0.4634146341463415,
      "grad_norm": 4.190999507904053,
      "learning_rate": 0.0001707317073170732,
      "loss": 0.5701944828033447,
      "step": 19
    },
    {
      "epoch": 0.4878048780487805,
      "grad_norm": 9.815690994262695,
      "learning_rate": 0.00016910569105691058,
      "loss": 0.6783714294433594,
      "step": 20
    },
    {
      "epoch": 0.5121951219512195,
      "grad_norm": 5.995128154754639,
      "learning_rate": 0.00016747967479674797,
      "loss": 0.6808998584747314,
      "step": 21
    },
    {
      "epoch": 0.5365853658536586,
      "grad_norm": 2.710401773452759,
      "learning_rate": 0.00016585365853658536,
      "loss": 0.66628098487854,
      "step": 22
    },
    {
      "epoch": 0.5609756097560976,
      "grad_norm": 6.826891899108887,
      "learning_rate": 0.00016422764227642277,
      "loss": 0.7973815202713013,
      "step": 23
    },
    {
      "epoch": 0.5853658536585366,
      "grad_norm": 7.411524295806885,
      "learning_rate": 0.00016260162601626016,
      "loss": 0.7496878504753113,
      "step": 24
    },
    {
      "epoch": 0.6097560975609756,
      "grad_norm": 7.1427693367004395,
      "learning_rate": 0.00016097560975609758,
      "loss": 0.736414909362793,
      "step": 25
    },
    {
      "epoch": 0.6341463414634146,
      "grad_norm": 2.9124326705932617,
      "learning_rate": 0.00015934959349593497,
      "loss": 0.642842173576355,
      "step": 26
    },
    {
      "epoch": 0.6585365853658537,
      "grad_norm": 3.3686037063598633,
      "learning_rate": 0.00015772357723577236,
      "loss": 0.5678421854972839,
      "step": 27
    },
    {
      "epoch": 0.6829268292682927,
      "grad_norm": 13.791831016540527,
      "learning_rate": 0.00015609756097560978,
      "loss": 0.6568776965141296,
      "step": 28
    },
    {
      "epoch": 0.7073170731707317,
      "grad_norm": 3.592717409133911,
      "learning_rate": 0.00015447154471544717,
      "loss": 0.6045543551445007,
      "step": 29
    },
    {
      "epoch": 0.7317073170731707,
      "grad_norm": 6.929385662078857,
      "learning_rate": 0.00015284552845528458,
      "loss": 0.6327217817306519,
      "step": 30
    },
    {
      "epoch": 0.7560975609756098,
      "grad_norm": 5.204023361206055,
      "learning_rate": 0.00015121951219512197,
      "loss": 0.7101250886917114,
      "step": 31
    },
    {
      "epoch": 0.7804878048780488,
      "grad_norm": 2.990781784057617,
      "learning_rate": 0.00014959349593495936,
      "loss": 0.7279523015022278,
      "step": 32
    },
    {
      "epoch": 0.8048780487804879,
      "grad_norm": 3.694549083709717,
      "learning_rate": 0.00014796747967479675,
      "loss": 0.7516610622406006,
      "step": 33
    },
    {
      "epoch": 0.8292682926829268,
      "grad_norm": 3.1634347438812256,
      "learning_rate": 0.00014634146341463414,
      "loss": 0.7732037305831909,
      "step": 34
    },
    {
      "epoch": 0.8536585365853658,
      "grad_norm": 4.521538734436035,
      "learning_rate": 0.00014471544715447156,
      "loss": 0.6389390230178833,
      "step": 35
    },
    {
      "epoch": 0.8780487804878049,
      "grad_norm": 7.572263717651367,
      "learning_rate": 0.00014308943089430895,
      "loss": 0.7142578959465027,
      "step": 36
    },
    {
      "epoch": 0.9024390243902439,
      "grad_norm": 13.04961109161377,
      "learning_rate": 0.00014146341463414634,
      "loss": 0.6616743803024292,
      "step": 37
    },
    {
      "epoch": 0.926829268292683,
      "grad_norm": 7.293030261993408,
      "learning_rate": 0.00013983739837398375,
      "loss": 0.5197018384933472,
      "step": 38
    },
    {
      "epoch": 0.9512195121951219,
      "grad_norm": 6.761922836303711,
      "learning_rate": 0.00013821138211382114,
      "loss": 0.5981365442276001,
      "step": 39
    },
    {
      "epoch": 0.975609756097561,
      "grad_norm": 6.090510845184326,
      "learning_rate": 0.00013658536585365856,
      "loss": 0.7853691577911377,
      "step": 40
    },
    {
      "epoch": 1.0,
      "grad_norm": 18.39741325378418,
      "learning_rate": 0.00013495934959349595,
      "loss": 0.9012986421585083,
      "step": 41
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.6097560975609756,
      "eval_loss": 0.6383993625640869,
      "eval_runtime": 3.1506,
      "eval_samples_per_second": 13.013,
      "eval_steps_per_second": 3.491,
      "step": 41
    }
  ],
  "logging_steps": 1,
  "max_steps": 123,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 21326681413632.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
